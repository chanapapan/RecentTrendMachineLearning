{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "after-oxide",
   "metadata": {},
   "source": [
    "# PART III : Predicting the language a surname comes from ( BATCHING )\n",
    "\n",
    "Previously, we train RNN by only inputing 1 sequence at a time. However, when we want to train the input data in batches a problem occurs because the length of the sequences are not equal so we cannot put the batch into a tensor.\n",
    "\n",
    "As a solution torch has a function called torch.nn.utils.rnn.pad_sequence which takes a list of tensors as inout and it will pad all of the sequence to the same length. Another problem is that calculating these can be computationally expensive since the sentence are all padded to the maximum length.\n",
    "\n",
    "So another function called torch.nn.utils.rnn.pack_padded_sequence is introduced. This function will pack the first sequences of each padded sequence together, and the second to gether and the third together, so forth. It will also output the batch size of each set of sequence so that the calculations can be more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-benefit",
   "metadata": {},
   "source": [
    "I adapted most of the code from here. : \n",
    "https://github.com/Niranjankumar-c/DeepLearning-PadhAI/blob/master/DeepLearning_Materials/8_RNN_LSTM_Model/BatchingSeqModels.ipynb\n",
    "\n",
    "I just changes our original input to be compatible with their implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pharmaceutical-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os, string, random, time, math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from get_free_gpu import get_free_gpu\n",
    "\n",
    "device = get_free_gpu()\n",
    "\n",
    "def findFiles(path):\n",
    "    return glob.glob(path)\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "\n",
    "n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "featured-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "meaningful-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('../../data/RNN/data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "    \n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-match",
   "metadata": {},
   "source": [
    "## Create a list containing all names and another list containing all the corresponding languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "everyday-graduate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20074\n",
      "20074\n"
     ]
    }
   ],
   "source": [
    "all_cats = list(category_lines.keys())\n",
    "all_names = []\n",
    "all_targets = []\n",
    "\n",
    "for i in all_cats:\n",
    "    for name in category_lines[i]:\n",
    "        all_names.append(name)\n",
    "    all_targets.append([i] * len(category_lines[i]))\n",
    "\n",
    "fin_targets = []    \n",
    "for j in range(len(all_targets)):\n",
    "    for k in all_targets[j]:\n",
    "        fin_targets.append(k)\n",
    "    \n",
    "print(len(all_names))\n",
    "print(len(fin_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-notice",
   "metadata": {},
   "source": [
    "## Split the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "premier-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_names, fin_targets, test_size = 0.2, random_state = 123, stratify = fin_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interstate-supplement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the training data:  16059\n",
      "The number of observations in the test data:  4015\n"
     ]
    }
   ],
   "source": [
    "#count\n",
    "print(\"The number of observations in the training data: \", len(X_train))\n",
    "print(\"The number of observations in the test data: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nonprofit-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_rep(name):\n",
    "    rep = torch.zeros(len(name), 1, n_letters) #Create a zeros tensor\n",
    "    #iterate through all the characters in the name\n",
    "    for index, letter in enumerate(name):\n",
    "        pos = all_letters.find(letter)\n",
    "        rep[index][0][pos] = 1 #Assign a value for each pos value\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nearby-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create vec representation of the language\n",
    "def lang_rep(lang):\n",
    "    return torch.tensor([all_categories.index(lang)], dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vocational-senegal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that their one-hot encoding function works\n",
    "name_rep(\"Fabby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "otherwise-input",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that their language to class number function works\n",
    "lang_rep(\"Korean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-prompt",
   "metadata": {},
   "source": [
    "## RNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "extended-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create simple rnn network \n",
    "class RNN_net(nn.Module):\n",
    "    #Create a constructor\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN_net, self).__init__()\n",
    "        self.hidden_size = hidden_size \n",
    "        self.rnn_cell = nn.RNN(input_size, hidden_size) # Applies a multi-layer Elman RNN with tanh or ReLU non-linearity to an input sequence.\n",
    "        self.h20 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    #create a forward pass function\n",
    "    def forward(self, input_, hidden = None, batch_size = 1):\n",
    "        out, hidden = self.rnn_cell(input_.to(device), hidden)\n",
    "        output = self.h20(hidden.view(-1, self.hidden_size))\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size = 1):\n",
    "        #function to init the hidden layers\n",
    "        return torch.zeros(1, batch_size, self.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-globe",
   "metadata": {},
   "source": [
    "## Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "patent-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to run inference\n",
    "def infer(net, name, device = device):\n",
    "    name_ohe = name_rep(name).to(device)\n",
    "\n",
    "    #get the output\n",
    "    output, hidden = net(name_ohe)\n",
    "\n",
    "    if type(hidden) is tuple: #for lSTM\n",
    "        hidden = hidden[0]\n",
    "    index = torch.argmax(hidden)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "corrected-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create hidden layers\n",
    "n_hidden = 128 #hidden layers count\n",
    "\n",
    "#initialize the network\n",
    "net = RNN_net(input_size=n_letters, hidden_size=n_hidden, output_size=n_categories).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "driving-performer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0165, -2.9141, -2.9239, -2.9212, -2.9115, -2.9406, -2.9432, -2.8423,\n",
       "         -2.7608, -3.0085, -2.8042, -2.7888, -2.7548, -2.9034, -2.8303, -3.0572,\n",
       "         -2.7881, -2.9897]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for inference\n",
    "infer(net, \"Fabby\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-seattle",
   "metadata": {},
   "source": [
    "## Function to randomly load npoints samples at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "capable-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(npoints, X_, y_):\n",
    "    \"\"\"Function to load the data\"\"\"\n",
    "    to_ret = []\n",
    "    for i in range(npoints):\n",
    "        index_ = np.random.randint(len(X_))\n",
    "        name, lang = X_[index_], y_[index_] #subset the data\n",
    "        to_ret.append((name, lang, name_rep(name), lang_rep(lang)))\n",
    "    \n",
    "    return to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "solid-highlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gou',\n",
       "  'Chinese',\n",
       "  tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]]]),\n",
       "  tensor([1])),\n",
       " ('Holman',\n",
       "  'English',\n",
       "  tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]]]),\n",
       "  tensor([4]))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader(2, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-johnson",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "prime-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an evaluation function \n",
    "\n",
    "def eval(net, n_points, topk, X_, y_, device = device):\n",
    "    \"Evaluation function\"\n",
    "\n",
    "    net = net.eval().to(device)\n",
    "    data_ = dataloader(n_points, X_, y_)\n",
    "    correct = 0\n",
    "\n",
    "    #iterate\n",
    "    for name, language, name_ohe, lang_rep in data_:\n",
    "    \n",
    "        name_ohe = name_ohe.to(device)\n",
    "        lang_rep = lang_rep.to(device)\n",
    "        \n",
    "        #get the output\n",
    "        output = infer(net, name, device)\n",
    "        val, indices = output.topk(topk) #get the top k values\n",
    "        indices = indices.to(device) #convert to devices\n",
    "        \n",
    "        if lang_rep in indices:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct/n_points\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "shared-forwarding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(net, 1000, 1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-flood",
   "metadata": {},
   "source": [
    "## Function for making a one hot encoder of a batch of names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "authentic-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a batched name rep\n",
    "\n",
    "def batched_name_rep(names, max_word_size):\n",
    "    rep = torch.zeros(max_word_size, len(names), n_letters)\n",
    "    for name_index, name in enumerate(names):\n",
    "        for letter_index, letter in enumerate(name):\n",
    "            pos = all_letters.find(letter)\n",
    "            rep[letter_index][name_index][pos] = 1\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "legal-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to print the output\n",
    "def print_char(name_reps):\n",
    "    name_reps = name_reps.view((-1, name_reps.size()[-1]))\n",
    "    for t in name_reps: \n",
    "        if torch.sum(t) == 0:\n",
    "            print('<pad>')\n",
    "        else:\n",
    "            index = t.argmax()\n",
    "            print(all_letters[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beginning-token",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n",
      "R\n",
      "h\n",
      "a\n",
      "y\n",
      "m\n",
      "a\n",
      "<pad>\n",
      "m\n",
      "<pad>\n"
     ]
    }
   ],
   "source": [
    "#example of batching\n",
    "\n",
    "out_ = batched_name_rep(['Shyam', 'Ram'], 5)\n",
    "print_char(out_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-genome",
   "metadata": {},
   "source": [
    "## Get the language of all the names in a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "animated-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_lang_rep(langs):\n",
    "    rep = torch.zeros([len(langs)], dtype=torch.long)\n",
    "    for index, lang in enumerate(langs):\n",
    "        rep[index] = all_categories.index(lang)\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-brunswick",
   "metadata": {},
   "source": [
    "## Function for downloading the sequences in batches with torch.nn.utils.rnn.pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "proprietary-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataloader\n",
    "def batched_dataloader(npoints, X_, y_, verbose=False, device = device):\n",
    "    names = []\n",
    "    langs = []\n",
    "    X_lengths = []\n",
    "    \n",
    "    for i in range(npoints):\n",
    "        index_ = np.random.randint(len(X_))\n",
    "        name, lang = X_[index_], y_[index_]\n",
    "        X_lengths.append(len(name))\n",
    "        names.append(name)\n",
    "        langs.append(lang)\n",
    "    max_length = max(X_lengths)\n",
    "    \n",
    "    names_rep = batched_name_rep(names, max_length).to(device)\n",
    "    langs_rep = batched_lang_rep(langs).to(device)\n",
    "    \n",
    "    padded_names_rep = torch.nn.utils.rnn.pack_padded_sequence(names_rep, X_lengths, enforce_sorted = False)\n",
    "    \n",
    "    if verbose:\n",
    "        print(names_rep.shape, padded_names_rep.data.shape)\n",
    "        print('--')\n",
    "    \n",
    "    if verbose:\n",
    "        print(names)\n",
    "        print_char(names_rep)\n",
    "        print('--')\n",
    "    \n",
    "    if verbose:\n",
    "        print_char(padded_names_rep.data)\n",
    "        print('Lang Rep', langs_rep.data)\n",
    "        print('Batch sizes', padded_names_rep.batch_sizes)\n",
    "    \n",
    "    \n",
    "    return padded_names_rep.to(device), langs_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "french-heather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 2, 57]) torch.Size([18, 57])\n",
      "--\n",
      "['Mozharovsky', 'Yarwood']\n",
      "M\n",
      "Y\n",
      "o\n",
      "a\n",
      "z\n",
      "r\n",
      "h\n",
      "w\n",
      "a\n",
      "o\n",
      "r\n",
      "o\n",
      "o\n",
      "d\n",
      "v\n",
      "<pad>\n",
      "s\n",
      "<pad>\n",
      "k\n",
      "<pad>\n",
      "y\n",
      "<pad>\n",
      "--\n",
      "M\n",
      "Y\n",
      "o\n",
      "a\n",
      "z\n",
      "r\n",
      "h\n",
      "w\n",
      "a\n",
      "o\n",
      "r\n",
      "o\n",
      "o\n",
      "d\n",
      "v\n",
      "s\n",
      "k\n",
      "y\n",
      "Lang Rep tensor([14,  4], device='cuda:1')\n",
      "Batch sizes tensor([2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PackedSequence(data=tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:1'), batch_sizes=tensor([2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1]), sorted_indices=tensor([0, 1], device='cuda:1'), unsorted_indices=tensor([0, 1], device='cuda:1')),\n",
       " tensor([14,  4], device='cuda:1'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dataloader(2, X_train, y_train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-onion",
   "metadata": {},
   "source": [
    "## Normal Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "desperate-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic train function\n",
    "def train(net, opt, criterion, n_points):\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    total_loss = 0\n",
    "    \n",
    "    data_ = dataloader(n_points, X_train, y_train)\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for name, language, name_ohe, lang_rep in data_:\n",
    "        \n",
    "        name_ohe = name_ohe.to(device)\n",
    "        lang_rep = lang_rep.to(device)\n",
    "        \n",
    "        hidden = net.init_hidden()\n",
    "\n",
    "        for i in range(name_ohe.size()[0]):\n",
    "            output, hidden = net(name_ohe[i:i+1], hidden)\n",
    "            \n",
    "        loss = criterion(output, lang_rep)\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        total_loss += loss\n",
    "        \n",
    "    opt.step()       \n",
    "    return total_loss/n_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-diabetes",
   "metadata": {},
   "source": [
    "## Define parameters for batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "pointed-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RNN_net(n_letters, n_hidden, n_categories).to(device)\n",
    "criterion = nn.NLLLoss().to(device)\n",
    "opt = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-phenomenon",
   "metadata": {},
   "source": [
    "## Batch Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "minus-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(net, opt, criterion, n_points, device = device):\n",
    "    \n",
    "    net.train().to(device)\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    batch_input, batch_groundtruth = batched_dataloader(n_points, X_train, y_train, False, device)\n",
    "    batch_input = batch_input.to(device)\n",
    "    batch_groundtruth = batch_groundtruth.to(device)\n",
    "    \n",
    "    output, hidden = net(batch_input)\n",
    "    \n",
    "    loss = criterion(output, batch_groundtruth)\n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-separation",
   "metadata": {},
   "source": [
    "## TRAIN !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "consolidated-manor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.4 s, sys: 81.2 ms, total: 2.48 s\n",
      "Wall time: 2.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.8295, device='cuda:1', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normal Training\n",
    "# %%time \n",
    "# #time for normal training\n",
    "# train(net, opt, criterion, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "furnished-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = device):\n",
    "    net = net.to(device)\n",
    "    criterion = nn.NLLLoss().to(device)\n",
    "    opt = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "    loss_arr = np.zeros(n_batches + 1)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device))/(i + 1)\n",
    "        \n",
    "        if i%display_freq == display_freq-1:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            print('Iteration', i, 'Loss', loss_arr[i])\n",
    "            # print('Top-1:', eval(net, len(X_test), 1, X_test, y_test), 'Top-2:', eval(net, len(X_test), 2, X_test, y_test))\n",
    "            plt.figure()\n",
    "            plt.plot(loss_arr[1:i], '-*')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.show()\n",
    "            print('\\n\\n')\n",
    "            \n",
    "    print('Top-1 Accuracy:', eval(net, len(X_test), 1, X_test, y_test, device), 'Top-2 Accuracy:', eval(net, len(X_test), 2, X_test, y_test, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "published-anime",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2999 Loss 0.45592594146728516\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f55700a3438>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Top-1 Accuracy: 0.7778331257783313 Top-2 Accuracy: 0.8727272727272727\n",
      "CPU times: user 6min 32s, sys: 2.84 s, total: 6min 35s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#training RNN using batch technique\n",
    "net = RNN_net(n_letters, 128, n_categories)\n",
    "train_setup(net, lr=0.15, n_batches=3000, batch_size = 512, display_freq=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-emerald",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-employer",
   "metadata": {},
   "source": [
    "In this part, we train RNN with 3000 batches of sequence, each with batch size 512. And it only takes 6.5 mins. Compared to normal training which would have taken more than 4 hours.\n",
    "\n",
    "This implementation is clearly more efficient and we can benefit from the GPU ( the results printed out as CPU times but as I have changed all the device to GPU it should mean the GPU time.)\n",
    "\n",
    "We got Top-1 accuracy of 77% and Top-2 accuracy of 87% which is quite good. The loss are also converging well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
