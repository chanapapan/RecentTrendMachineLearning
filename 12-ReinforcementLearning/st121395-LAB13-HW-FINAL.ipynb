{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN for TIC-TAC-TOE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first attempt, we might convert the input state-action pairs to a binary representation and use a linear output for the Q value.\n",
    "\n",
    "We would use a one-hot representation for each of the 9 game cells in s (3 choices) and the 9 possible actions. This would give us 36 inputs.\n",
    "\n",
    "The neural network would be multi-layer. With two fully connected layers of 10 units each, we'd have 10x37+10x11+11=491 parameters.\n",
    "\n",
    "However, take a look at DQN. Their model has a NN to process the input images from the Atari console and has one output for each possible action.\n",
    "\n",
    "With this approach, we would have just 27 inputs and 9 outputs.\n",
    "\n",
    "Two fully connected layers of 10 units each would give us 10 x 28 + 10 x 11 + 9 x 11 = 489 parameters, which is similar in size to the above and has the advantage of only\n",
    "having to be executed once to get the value of every action.\n",
    "\n",
    "So, the first step will be to replace the Q table with a Q network. Go ahead and write your network class in PyTorch.\n",
    "\n",
    "\n",
    "Deep Q-Learning\n",
    "\n",
    "Alright, you have a neural network to replace the Q table, but how to learn its parameters?\n",
    "\n",
    "Take a look again at Mnih et al. (2015). The method they recommend is experience replay in which they store recent state-action-reward tuples in a buffer and train on random subsamples from the buffer.\n",
    "\n",
    "You'll have to decide some things, such as what to do if the agent samples an illegal move. Give a negative reward? Give a 0 reward? Think about it and try an approach.\n",
    "\n",
    "Go ahead and write the DQN algorithm, using your simple fully connected network in place of the CNN. Get it learning!\n",
    "\n",
    "Report on your experiments and results by next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import importlib\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from collections import deque\n",
    "from tqdm import trange\n",
    "\n",
    "# Select GPU or CPU as device\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(episode, rewards, losses):\n",
    "    # clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('episode %s. reward: %s' % (episode, np.mean(rewards[-10:])))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)   \n",
    "    plt.show() \n",
    "\n",
    "\n",
    "def gen_eps_by_episode(epsilon_start, epsilon_final, epsilon_decay):\n",
    "    eps_by_episode = lambda episode: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * episode / epsilon_decay)\n",
    "    return eps_by_episode\n",
    "\n",
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 500\n",
    "eps_by_episode = gen_eps_by_episode(epsilon_start, epsilon_final, epsilon_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        # Add batch index dimension to state representations\n",
    "        state = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)            \n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_state, n_action):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=n_state, out_features=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=10, out_features=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=10, out_features=n_action))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def act(self, state, epsilon):\n",
    "        # Get an epsilon greedy action for given state\n",
    "        if random.random() > epsilon: # Use argmax_a Q(s,a)\n",
    "            state = autograd.Variable(torch.Tensor(state).unsqueeze(0)).to(device)\n",
    "#             print(state.shape)\n",
    "            q_value = self.forward(state)\n",
    "            q_value = q_value.cpu()\n",
    "#             print(q_value.shape)\n",
    "            action = q_value.max(1)[1].item()            \n",
    "        else: # get random action\n",
    "#             action = random.randrange(env.action_space.n)\n",
    "            action = random.randrange(9)\n",
    "        return action\n",
    "    \n",
    "    def get_q_value(self, state):\n",
    "        state = autograd.Variable(torch.Tensor(state).unsqueeze(0)).to(device)\n",
    "#             print(state.shape)\n",
    "        q_value = self.forward(state)\n",
    "        q_value = q_value.cpu()\n",
    "#             print(q_value.shape)\n",
    "        action = q_value.max(1)[1].item() \n",
    "        \n",
    "        return q_value, action\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_td_loss(model, batch_size, gamma=0.99):\n",
    "\n",
    "    # Get batch from replay buffer\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    # Convert to tensors. Creating Variables is not necessary with more recent PyTorch versions.\n",
    "    state      = torch.Tensor(np.float32(state)).to(device)\n",
    "    next_state = torch.Tensor(np.float32(next_state)).to(device)\n",
    "    action     = torch.Tensor(action).long().to(device)\n",
    "    reward     = torch.Tensor(reward).to(device)\n",
    "    done       = torch.Tensor(done).to(device)\n",
    "\n",
    "    # Calculate Q(s) and Q(s')\n",
    "    q_values      = model(state)\n",
    "    next_q_values = model(next_state)\n",
    "    \n",
    "#     print(q_values.shape)\n",
    "\n",
    "    # Get Q(s,a) and max_a' Q(s',a')\n",
    "#     q_value          = q_values.gather(1, action).squeeze(1)\n",
    "    q_value          = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "    next_q_value     = next_q_values.max(1)[0]\n",
    "    # Calculate target for Q(s,a): r + gamma max_a' Q(s',a')\n",
    "    # Note that the done signal is used to terminate recursion at end of episode.\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "    \n",
    "    # Calculate MSE loss. Variables are not needed in recent PyTorch versions.\n",
    "    loss = (q_value - autograd.Variable(expected_q_value.data)).pow(2).mean()\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, model, eps_by_episode, optimizer, replay_buffer, episodes = 10000, batch_size=32, gamma = 0.99):\n",
    "    losses = []\n",
    "    all_rewards = []\n",
    "    episode_reward = 0\n",
    "    tot_reward = 0\n",
    "    tr = trange(episodes+1, desc='Agent training', leave=True)\n",
    "\n",
    "    # Get initial state input\n",
    "    state = env.reset()\n",
    "    state = state.reshape(27)\n",
    "\n",
    "    # Execute episodes iterations\n",
    "    for episode in tr:\n",
    "        tr.set_description(\"Agent training (episode{}) Avg Reward {}\".format(episode+1,tot_reward/(episode+1)))\n",
    "        tr.refresh() \n",
    "\n",
    "        # Get initial epsilon greedy action\n",
    "        epsilon = eps_by_episode(episode)\n",
    "        state = state.reshape(27)\n",
    "        \n",
    "        action = model.act(state, epsilon)\n",
    "        \n",
    "        # Take a step\n",
    "#         next_state, reward, done, _ = env.step(action)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        next_state = next_state.reshape(27)\n",
    "\n",
    "        # Append experience to replay buffer\n",
    "        replay_buffer.push(state, action, reward, next_state, done)\n",
    "\n",
    "        tot_reward += reward\n",
    "        episode_reward += reward\n",
    "        \n",
    "        state = next_state\n",
    "\n",
    "        # Start a new episode if done signal is received\n",
    "        if done:\n",
    "            state = env.reset()\n",
    "            all_rewards.append(episode_reward)\n",
    "            episode_reward = 0\n",
    "\n",
    "        # Train on a batch if we've got enough experience\n",
    "        if len(replay_buffer) > batch_size:\n",
    "            loss = compute_td_loss(model, batch_size, gamma)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "    plot(episode, all_rewards, losses)  \n",
    "    return model, all_rewards, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from games.abstract_game import AbstractGame\n",
    "\n",
    "game_name = 'tictactoe'\n",
    "game_module = importlib.import_module(\"games.\" + game_name) \n",
    "\n",
    "env = game_module.Game()\n",
    "\n",
    "model = DQN(27, 9).to(device)\n",
    "    \n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "replay_buffer = ReplayBuffer(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Agent training (episode1000001) Avg Reward 0.17766682233317765: 100%|██████| 1000001/1000001 [2:51:30<00:00, 97.18it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, all_rewards, losses = train(env, model, eps_by_episode, optimizer, replay_buffer, episodes = 1000000, batch_size=32, gamma = 0.99)\n",
    "torch.save(model.state_dict(), 'weights/tictactoe-fcdqn-1M.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |   |   \n",
      "---+---+---\n",
      "   |   |   \n",
      "---+---+---\n",
      "   | O |   \n",
      "   |   |   \n",
      "---+---+---\n",
      "   |   | X \n",
      "---+---+---\n",
      "   | O |   \n",
      "   | O |   \n",
      "---+---+---\n",
      "   |   | X \n",
      "---+---+---\n",
      "   | O |   \n",
      " X | O |   \n",
      "---+---+---\n",
      "   |   | X \n",
      "---+---+---\n",
      "   | O |   \n",
      " X | O |   \n",
      "---+---+---\n",
      "   | O | X \n",
      "---+---+---\n",
      "   | O |   \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def play_game(model):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    state = state.reshape(27)\n",
    "\n",
    "    while(not done):\n",
    "        action = model.act(state, epsilon_final)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        next_state = next_state.reshape(27)\n",
    "\n",
    "        env.render()\n",
    "        time.sleep(0.03)\n",
    "        state = next_state\n",
    "\n",
    "play_game(model)\n",
    "time.sleep(3)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & Try the model with these patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=27, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=10, out_features=9, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math, random\n",
    "import importlib\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from collections import deque\n",
    "from tqdm import trange\n",
    "\n",
    "# Select GPU or CPU as device\n",
    "\n",
    "device = 'cpu'\n",
    "epsilon_final = 0.01\n",
    "\n",
    "from games.abstract_game import AbstractGame\n",
    "\n",
    "game_name = 'tictactoe'\n",
    "game_module = importlib.import_module(\"games.\" + game_name) \n",
    "\n",
    "env = game_module.Game()\n",
    "\n",
    "model = DQN(27, 9).to(device)\n",
    "model.load_state_dict(torch.load('weights/tictactoe-fcdqn-1M.pth', map_location=torch.device('cpu') ),)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O |   |   \n",
      "---+---+---\n",
      "   |   |   \n",
      "---+---+---\n",
      "   |   |   \n",
      "torch.Size([1, 9])\n",
      "tensor(-0.7885, grad_fn=<SelectBackward>)\n",
      "tensor(-0.8351, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "state = state.reshape(27)\n",
    "\n",
    "# create the first state\n",
    "state, reward, done = env.step(0)\n",
    "env.render()\n",
    "\n",
    "state = state.reshape(27)\n",
    "\n",
    "q_value, action = model.get_q_value(state)\n",
    "\n",
    "print(q_value.shape)\n",
    "print(q_value[0][4])\n",
    "print(q_value[0][5])\n",
    "\n",
    "# next_state, reward, done = env.step(5)\n",
    "# print(next_state, 'reward', reward, 'is_done:', done)\n",
    "\n",
    "# action = model.act(state, epsilon_final)\n",
    "# next_state, reward, done = env.step(action)\n",
    "# next_state = next_state.reshape(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
